# ChefBot Architecture Overview

**Last Updated**: November 9, 2025  
**Version**: 2.0 (Enhanced UI with File Uploads)

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       USER INTERFACE                            â”‚
â”‚                  (enhanced_ui.py - Flask)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Chat Input  â”‚  â”‚ PDF Upload   â”‚  â”‚ Image Upload â”‚         â”‚
â”‚  â”‚  (AJAX/JSON) â”‚  â”‚  (PyPDF2)    â”‚  â”‚ (Tesseract)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  RAG Toggle  â”‚  â”‚ Clear Memory â”‚  â”‚  View Stats  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CHEFBOT RAG ENGINE                        â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚             CONVERSATIONAL MEMORY                        â”‚  â”‚
â”‚  â”‚       (ConversationBufferMemory - Last 5 turns)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            QUERY PROCESSING & EMBEDDING                  â”‚  â”‚
â”‚  â”‚  â€¢ User question                                         â”‚  â”‚
â”‚  â”‚  â€¢ Convert to 384-dim vector                             â”‚  â”‚
â”‚  â”‚  â€¢ GPU/CPU acceleration                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         CONTEXT RETRIEVAL (RAG) - Toggle ON/OFF          â”‚  â”‚
â”‚  â”‚  â€¢ Semantic search in Weaviate (cosine similarity)       â”‚  â”‚
â”‚  â”‚  â€¢ Retrieve top-2 relevant chunks (configurable)         â”‚  â”‚
â”‚  â”‚  â€¢ Include metadata (source, content)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            PROMPT CONSTRUCTION                           â”‚  â”‚
â”‚  â”‚  System Prompt + Context + History + Question            â”‚  â”‚
â”‚  â”‚  â†’ Formatted for Phi-2                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       LLM GENERATION (Microsoft Phi-2 - 2.7B)            â”‚  â”‚
â”‚  â”‚  â€¢ 8-bit quantization for 4GB VRAM                       â”‚  â”‚
â”‚  â”‚  â€¢ CPU offloading enabled                                â”‚  â”‚
â”‚  â”‚  â€¢ Max 512 tokens, temp 0.7                              â”‚  â”‚
â”‚  â”‚  â€¢ Context-aware response generation                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â†“
                     Generated Answer
```

## ğŸ”„ RAG Pipeline Flow

```
User Question: "How do I make pizza dough?"
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDING MODEL    â”‚
â”‚  (MiniLM-L6-v2)     â”‚  Converts question â†’ [384-dim vector]
â”‚  Device: GPU/CPU    â”‚  e.g., [0.23, -0.15, 0.87, ..., 0.42]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WEAVIATE DB       â”‚
â”‚  (Vector Search)    â”‚  Cosine similarity search
â”‚  localhost:8080     â”‚
â”‚                     â”‚
â”‚  Chunk 1: 0.89 sim  â”‚  "Pizza dough requires flour, water..."
â”‚  Chunk 2: 0.85 sim  â”‚  "Mix ingredients, knead for 10 mins..."
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONTEXT BUILDER    â”‚  Combines:
â”‚                     â”‚  â€¢ Top-2 retrieved chunks
â”‚                     â”‚  â€¢ Last 5 conversation turns
â”‚                     â”‚  â€¢ System instructions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PHI-2 MODEL       â”‚  Generates answer using:
â”‚  (2.7B params)      â”‚  â€¢ Retrieved context
â”‚  8-bit quantized    â”‚  â€¢ Conversation history
â”‚  4GB VRAM optimized â”‚  â€¢ Model's knowledge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Answer: "To make pizza dough, you'll need 3 cups flour..."
```

## ğŸ“¦ Component Breakdown

### 1. **Weaviate (Vector Database)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         WEAVIATE v1.23.7         â”‚
â”‚  Running on: localhost:8080      â”‚
â”‚  Running in: Docker              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Collection: CookingKnowledge    â”‚
â”‚                                  â”‚
â”‚  Schema:                         â”‚
â”‚  â”œâ”€ content (text)               â”‚
â”‚  â”‚   - Stores text chunks        â”‚
â”‚  â”‚   - Max ~800 characters       â”‚
â”‚  â”‚                               â”‚
â”‚  â”œâ”€ source (text)                â”‚
â”‚  â”‚   - Origin filename           â”‚
â”‚  â”‚   - e.g., "cooking_knowledge" â”‚
â”‚  â”‚                               â”‚
â”‚  â””â”€ vector (384 dimensions)      â”‚
â”‚      - Semantic embedding        â”‚
â”‚      - Generated by MiniLM       â”‚
â”‚                                  â”‚
â”‚  Operations:                     â”‚
â”‚  â€¢ add_document() - Add content  â”‚
â”‚  â€¢ retrieve_context() - Search   â”‚
â”‚  â€¢ Cosine similarity matching    â”‚
â”‚  â€¢ Sub-second query performance  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Embedding Model**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sentence-transformers/          â”‚
â”‚  all-MiniLM-L6-v2                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Specifications:                 â”‚
â”‚  â€¢ Output: 384 dimensions        â”‚
â”‚  â€¢ Model size: ~100MB            â”‚
â”‚  â€¢ Speed: ~1000 sentences/sec    â”‚
â”‚  â€¢ Device: CUDA or CPU           â”‚
â”‚                                  â”‚
â”‚  Conversion Process:             â”‚
â”‚  Text â†’ Tokenization â†’ Model     â”‚
â”‚       â†’ 384D Vector              â”‚
â”‚                                  â”‚
â”‚  Example:                        â”‚
â”‚  "Pizza dough"                   â”‚
â”‚    â†“                             â”‚
â”‚  [0.23, -0.15, 0.87, ..., 0.42]  â”‚
â”‚                                  â”‚
â”‚  Similarity Calculation:         â”‚
â”‚  cosine_similarity(vec1, vec2)   â”‚
â”‚  â†’ Score between 0 and 1         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. **LLM (Microsoft Phi-2)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Microsoft Phi-2               â”‚
â”‚      (2.7 Billion Parameters)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Optimizations:                    â”‚
â”‚  âœ“ 8-bit quantization (load_in_8bit)â”‚
â”‚  âœ“ CPU offloading for 4GB VRAM    â”‚
â”‚  âœ“ Device map: auto               â”‚
â”‚  âœ“ Trust remote code: enabled     â”‚
â”‚                                    â”‚
â”‚  Hardware Support:                 â”‚
â”‚  â€¢ GPU: NVIDIA RTX 3050+ (4GB)    â”‚
â”‚  â€¢ CPU: Fallback mode available   â”‚
â”‚  â€¢ Memory: ~3GB VRAM + 4GB RAM    â”‚
â”‚                                    â”‚
â”‚  Generation Settings:              â”‚
â”‚  â€¢ Max tokens: 512                â”‚
â”‚  â€¢ Temperature: 0.7               â”‚
â”‚  â€¢ Top-k: 50                      â”‚
â”‚  â€¢ Top-p: 0.95                    â”‚
â”‚  â€¢ Repetition penalty: 1.1        â”‚
â”‚                                    â”‚
â”‚  Performance:                      â”‚
â”‚  â€¢ GPU: 5-15 seconds/response     â”‚
â”‚  â€¢ CPU: 30-60 seconds/response    â”‚
â”‚                                    â”‚
â”‚  Input: Formatted prompt           â”‚
â”‚  Output: Generated text response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. **Memory System**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ConversationBufferMemory          â”‚
â”‚   (LangChain)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Configuration:                     â”‚
â”‚  â€¢ Stores last 5 conversation turnsâ”‚
â”‚  â€¢ Return messages: True            â”‚
â”‚  â€¢ Memory key: "chat_history"       â”‚
â”‚                                     â”‚
â”‚  Storage Format:                    â”‚
â”‚  Turn 1:                            â”‚
â”‚    Human: "How to make pasta?"      â”‚
â”‚    AI: "Here's how to make pasta..."â”‚
â”‚                                     â”‚
â”‚  Turn 2:                            â”‚
â”‚    Human: "What about sauce?"       â”‚
â”‚    AI: "For the sauce you mentionedâ”‚
â”‚         with pasta..."              â”‚
â”‚                                     â”‚
â”‚  Features:                          â”‚
â”‚  â€¢ Context continuity               â”‚
â”‚  â€¢ Follow-up questions              â”‚
â”‚  â€¢ Clear memory function            â”‚
â”‚  â€¢ Automatic truncation at 5 turns  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. **OCR Engine (Tesseract)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tesseract OCR v5.4.0              â”‚
â”‚   (Google's Open Source OCR)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Installation Path (Windows):       â”‚
â”‚  C:\Program Files\Tesseract-OCR\    â”‚
â”‚                                     â”‚
â”‚  Supported Formats:                 â”‚
â”‚  â€¢ PNG, JPG, JPEG                   â”‚
â”‚  â€¢ Recipe cards                     â”‚
â”‚  â€¢ Printed text                     â”‚
â”‚  â€¢ Handwriting (limited)            â”‚
â”‚                                     â”‚
â”‚  Process:                           â”‚
â”‚  Image â†’ PIL.Image.open()           â”‚
â”‚       â†’ pytesseract.image_to_string()â”‚
â”‚       â†’ Extracted text              â”‚
â”‚                                     â”‚
â”‚  Performance:                       â”‚
â”‚  â€¢ Speed: 3-8 seconds/image         â”‚
â”‚  â€¢ Accuracy: ~90% on clear text     â”‚
â”‚                                     â”‚
â”‚  Error Handling:                    â”‚
â”‚  â€¢ Path validation                  â”‚
â”‚  â€¢ Clear error messages             â”‚
â”‚  â€¢ Installation instructions        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”€ Data Flow: Upload PDF

```
User uploads PDF via Flask UI
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   secure_filename()  â”‚  Sanitize filename
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PyPDF2.PdfReader  â”‚  Extract all text from pages
â”‚                     â”‚  Combines all pages into single text
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Splitter      â”‚  RecursiveCharacterTextSplitter
â”‚  Chunk size: 800    â”‚  â€¢ Break into 800-char chunks
â”‚  Overlap: 100       â”‚  â€¢ 100-char overlap for context
â”‚                     â”‚  â€¢ Smart splitting at sentences
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  For each chunk:    â”‚
â”‚  1. Generate vector â”‚  MiniLM â†’ [384-dim array]
â”‚  2. Create object   â”‚  {content, source, vector}
â”‚  3. Store in DB     â”‚  Weaviate.batch.add_data_object()
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
   âœ… Indexed & Searchable
   Total chunks stored in database
```

## ğŸ”€ Data Flow: Upload Image

```
User uploads Image (PNG/JPG) via Flask UI
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Validation    â”‚  Check extension, size
â”‚  secure_filename()  â”‚  Sanitize filename
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIL.Image.open()   â”‚  Load image
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tesseract OCR      â”‚  Extract text from image
â”‚  (pytesseract)      â”‚  â€¢ Handles multiple fonts
â”‚                     â”‚  â€¢ Recipe cards, printed text
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Splitter      â”‚  Break into 800-char chunks
â”‚                     â”‚  with 100-char overlap
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding + Store  â”‚  Generate vectors & index
â”‚                     â”‚  Store in Weaviate
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
   âœ… Indexed & Searchable
```

## ğŸ”€ Data Flow: Chat Query (RAG Mode ON)

```
User: "How to make carbonara?"
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Flask)   â”‚  POST /chat
â”‚  AJAX Request       â”‚  {message, use_rag: true}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  get_bot()          â”‚  Lazy load ChefBotRAG
â”‚  (Singleton)        â”‚  (30-60s first time)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  query_with_rag()   â”‚  Main RAG pipeline
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embed Query        â”‚  "carbonara" â†’ [0.15, -0.22, ...]
â”‚  MiniLM Model       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Weaviate Search    â”‚  Cosine similarity search
â”‚  Top-2 Results      â”‚  Returns most relevant chunks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Build Prompt       â”‚  System + Context + History + Q
â”‚                     â”‚  Formatted for Phi-2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phi-2 Generation   â”‚  Generate answer (5-15s GPU)
â”‚  Max 512 tokens     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Save to Memory     â”‚  Store Q&A in buffer
â”‚  (Last 5 turns)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
   Response â†’ Flask â†’ Frontend
   Display in chat UI
```

## ğŸ”€ Data Flow: Chat Query (RAG Mode OFF)

```
User: "Tell me about Italian cuisine"
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Flask)   â”‚  POST /chat
â”‚  AJAX Request       â”‚  {message, use_rag: false}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  query()            â”‚  Direct LLM query
â”‚  (No RAG)           â”‚  Skips vector search
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Build Prompt       â”‚  System + History + Question
â”‚                     â”‚  No context retrieval
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phi-2 Generation   â”‚  Pure model knowledge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Save to Memory     â”‚  Store in conversation buffer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
   Response â†’ Frontend
```

## ğŸ¯ Why This Architecture?

### 1. **Separation of Concerns**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer            â”‚  File        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Presentation     â”‚  enhanced_ui â”‚  Flask web UI, file handling
â”‚  Business Logic   â”‚  app.py      â”‚  RAG engine, LLM, memory
â”‚  Data Storage     â”‚  Weaviate    â”‚  Vector database
â”‚  Infrastructure   â”‚  Docker      â”‚  Container orchestration
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Modularity & Extensibility**
- âœ… **Easy LLM swapping**: Change `model_name` in app.py
- âœ… **UI independence**: Flask can be replaced with Gradio/Streamlit
- âœ… **Database flexibility**: Weaviate can be swapped for Pinecone/Chroma
- âœ… **Embedding models**: Change sentence-transformers model easily

### 3. **Scalability Considerations**
```
Current Capacity:
â”œâ”€ Weaviate: Millions of vectors supported
â”œâ”€ Embeddings: 1000+ sentences/second
â”œâ”€ LLM: Stateless (can serve multiple users)
â””â”€ Memory: Isolated per session

Scaling Options:
â”œâ”€ Horizontal: Multiple Flask instances + load balancer
â”œâ”€ Vertical: Better GPU (8GB+ VRAM, no quantization)
â”œâ”€ Distributed: Weaviate cluster for large datasets
â””â”€ Caching: Redis for frequent queries
```

### 4. **Performance Optimizations**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Optimization         â”‚  Impact     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  8-bit quantization   â”‚  50% memory â”‚
â”‚  CPU offloading       â”‚  4GB GPU OK â”‚
â”‚  Lazy loading         â”‚  Fast start â”‚
â”‚  Vector indexing      â”‚  <1s search â”‚
â”‚  Batch embeddings     â”‚  3x faster  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. **Local-First Philosophy**
```
Why Local?
âœ… Privacy: Data never leaves your machine
âœ… No API costs: Zero ongoing fees
âœ… Offline capable: Works without internet
âœ… Customizable: Full control over models
âœ… Fast: No network latency
âœ… Secure: No data breaches possible
```

## ğŸ“Š Performance Characteristics

### First-Time Startup (Cold Start)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Task                 â”‚  Time    â”‚  Size     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Phi-2 Download       â”‚  10-20m  â”‚  5.5 GB   â”‚
â”‚  MiniLM Download      â”‚  1-2m    â”‚  100 MB   â”‚
â”‚  Weaviate Start       â”‚  10-30s  â”‚  Docker   â”‚
â”‚  Model Loading (GPU)  â”‚  30-45s  â”‚  RAM      â”‚
â”‚  Model Loading (CPU)  â”‚  45-90s  â”‚  RAM      â”‚
â”‚  Schema Creation      â”‚  1-2s    â”‚  N/A      â”‚
â”‚  Initial Index        â”‚  30-60s  â”‚  1000 docsâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTAL (first time)   â”‚  15-25m  â”‚  ~6 GB    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Subsequent Runs (Warm Start)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Task                 â”‚  Time    â”‚  Notes    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Weaviate Start       â”‚  5-10s   â”‚  If stoppedâ”‚
â”‚  Model Loading (GPU)  â”‚  20-30s  â”‚  From diskâ”‚
â”‚  Model Loading (CPU)  â”‚  30-60s  â”‚  From diskâ”‚
â”‚  Flask Server Start   â”‚  2-3s    â”‚  Instant  â”‚
â”‚  First Query (lazy)   â”‚  30-45s  â”‚  +load botâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTAL (warm start)   â”‚  30-60s  â”‚  Typical  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Runtime Performance (GPU - RTX 3050)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Operation            â”‚  Time    â”‚  Notes    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chat query (RAG ON)  â”‚  5-15s   â”‚  Normal   â”‚
â”‚  Chat query (RAG OFF) â”‚  3-8s    â”‚  Faster   â”‚
â”‚  Embedding generation â”‚  10-50ms â”‚  Per queryâ”‚
â”‚  Vector search        â”‚  50-200msâ”‚  Weaviate â”‚
â”‚  LLM generation       â”‚  4-12s   â”‚  Main timeâ”‚
â”‚  PDF upload (10 pages)â”‚  3-8s    â”‚  Extract  â”‚
â”‚  Image OCR            â”‚  3-8s    â”‚  Per imageâ”‚
â”‚  Memory save          â”‚  <10ms   â”‚  Fast     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Runtime Performance (CPU - Fallback)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Operation            â”‚  Time    â”‚  Notes    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chat query (RAG ON)  â”‚  30-90s  â”‚  Slower   â”‚
â”‚  Chat query (RAG OFF) â”‚  20-60s  â”‚  Still slowâ”‚
â”‚  Embedding generation â”‚  100-300msâ”‚ Manageableâ”‚
â”‚  Vector search        â”‚  50-200msâ”‚  Same     â”‚
â”‚  LLM generation       â”‚  25-80s  â”‚  Bottleneckâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Usage
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Component            â”‚  GPU     â”‚  RAM      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Phi-2 (8-bit)        â”‚  3.2 GB  â”‚  1 GB     â”‚
â”‚  Phi-2 (16-bit, CPU)  â”‚  N/A     â”‚  6 GB     â”‚
â”‚  MiniLM Embeddings    â”‚  0.3 GB  â”‚  0.5 GB   â”‚
â”‚  Weaviate (100K docs) â”‚  N/A     â”‚  2-4 GB   â”‚
â”‚  Flask + System       â”‚  N/A     â”‚  1-2 GB   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTAL (GPU mode)     â”‚  ~3.5 GB â”‚  ~5 GB    â”‚
â”‚  TOTAL (CPU mode)     â”‚  0 GB    â”‚  ~10 GB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Security & Privacy Considerations

### Current Setup: 100% Local
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Component         â”‚  Location  â”‚  Network  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Weaviate DB       â”‚  localhost â”‚  :8080    â”‚
â”‚  Flask Web Server  â”‚  localhost â”‚  :5000    â”‚
â”‚  Phi-2 Model       â”‚  Local GPU â”‚  None     â”‚
â”‚  Embeddings        â”‚  Local GPU â”‚  None     â”‚
â”‚  User Files        â”‚  Temp dir  â”‚  None     â”‚
â”‚  Conversations     â”‚  RAM only  â”‚  None     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… No external API calls
âœ… No data leaves your machine
âœ… No telemetry or tracking
âœ… Works fully offline (after setup)
âœ… No authentication needed (single user)
```

### Security Features
```
File Upload Security:
â”œâ”€ Filename sanitization (secure_filename)
â”œâ”€ Extension validation (.pdf, .png, .jpg only)
â”œâ”€ Size limit (16MB max)
â”œâ”€ Temporary storage only
â””â”€ No arbitrary code execution

Database Security:
â”œâ”€ Local-only access (no external exposure)
â”œâ”€ Anonymous access (single-user mode)
â”œâ”€ No persistent credentials
â””â”€ Data in Docker volume (isolated)

Web Server Security:
â”œâ”€ Development server (not production)
â”œâ”€ Localhost binding only
â”œâ”€ CSRF protection (built-in Flask)
â””â”€ No user authentication (local use)
```

### Production Hardening (If Deploying)
```
âš ï¸  Current setup is for LOCAL USE ONLY

For production deployment, add:
â”œâ”€ Authentication: User login, session management
â”œâ”€ HTTPS: SSL/TLS certificates
â”œâ”€ Weaviate Security: API keys, authentication
â”œâ”€ Rate Limiting: Prevent abuse
â”œâ”€ Input Validation: Sanitize all inputs
â”œâ”€ WSGI Server: Gunicorn/uWSGI instead of Flask dev
â”œâ”€ Reverse Proxy: Nginx for load balancing
â”œâ”€ Monitoring: Logging, alerting, metrics
â”œâ”€ Backup: Database backup strategy
â””â”€ Updates: Regular security patches
```

### Privacy Guarantees
```
âœ… Your recipe uploads stay on your computer
âœ… Your questions never sent to external APIs
âœ… No cookies or tracking
âœ… No data collection
âœ… No model fine-tuning on your data
âœ… Memory cleared on restart
âœ… No persistent conversation logs (unless you save them)
```

## ğŸ”„ Typical Conversation Flow Examples

### Example 1: Basic Recipe Query (RAG Mode)
```
1. User: "How do I sautÃ© vegetables?"
   
   Process:
   â”œâ”€ Embed: "sautÃ© vegetables" â†’ vector
   â”œâ”€ Search: Weaviate finds relevant chunks
   â”‚   â€¢ "SautÃ©ing is a cooking technique..." (0.91 similarity)
   â”‚   â€¢ "Heat oil in pan, add vegetables..." (0.87 similarity)
   â”œâ”€ Build prompt with context
   â””â”€ Phi-2 generates: 
       "To sautÃ© vegetables, heat 2 tbsp oil in a large pan over 
        medium-high heat. Add harder vegetables first (carrots, 
        broccoli), cook 3-4 mins. Add softer ones (peppers, 
        mushrooms) and cook until tender-crisp, about 5-7 mins 
        total. Season with salt and pepper."

2. User: "What temperature should I use?"
   
   Process:
   â”œâ”€ Memory recalls: Previous Q about sautÃ©ing
   â”œâ”€ Search: "sautÃ© temperature" in context
   â”œâ”€ Phi-2 (with context):
       "For sautÃ©ing vegetables that you asked about, use 
        medium-high heat, around 350-375Â°F (175-190Â°C). This 
        allows quick cooking while maintaining texture."

3. User: "Any tips for beginners?"
   
   Process:
   â”œâ”€ Full conversation context maintained
   â”œâ”€ Builds on sautÃ©ing topic
   â””â”€ Phi-2 generates:
       "For sautÃ©ing vegetables as a beginner: 1) Don't 
        overcrowd the pan, 2) Keep ingredients moving, 3) Have 
        all ingredients prepped, 4) Use high smoke-point oils 
        like vegetable or canola."
```

### Example 2: PDF Upload â†’ Query Flow
```
1. User uploads: "italian_recipes.pdf" (15 pages)
   
   Process:
   â”œâ”€ Extract text: 12,450 characters
   â”œâ”€ Split into chunks: 18 chunks created
   â”œâ”€ Generate embeddings: 18 vectors
   â”œâ”€ Store in Weaviate: Success
   â””â”€ Response: "âœ… Added 18 chunks from italian_recipes.pdf"

2. User: "What's the authentic carbonara recipe?"
   
   Process:
   â”œâ”€ Search newly indexed content
   â”œâ”€ Find: Carbonara recipe chunk (0.94 similarity)
   â””â”€ Phi-2 generates:
       "According to the Italian recipe guide you uploaded, 
        authentic carbonara uses guanciale (cured pork jowl), 
        eggs, Pecorino Romano cheese, and black pepper. No 
        cream! Mix egg yolks with grated cheese, cook pasta, 
        crisp guanciale, toss together off heat."
```

### Example 3: Image OCR â†’ Query Flow
```
1. User uploads: "grandmas_recipe_card.jpg"
   
   Process:
   â”œâ”€ Tesseract OCR extracts text:
   â”‚   "Grandma's Apple Pie
   â”‚    Ingredients: 6 apples, 2 cups flour, 1 cup sugar...
   â”‚    Instructions: Peel and slice apples..."
   â”œâ”€ Split into chunks: 3 chunks
   â”œâ”€ Index in Weaviate
   â””â”€ Response: "âœ… Extracted 245 characters, added 3 chunks"

2. User: "What apples did grandma use?"
   
   Process:
   â”œâ”€ Search: Finds recipe card chunk
   â””â”€ Phi-2 generates:
       "Based on the recipe card image you uploaded, your 
        grandma's apple pie used 6 apples. The recipe suggests 
        Granny Smith or Honeycrisp for best results."
```

### Example 4: RAG Toggle Comparison
```
RAG Mode ON (Default):
User: "How to make bread dough?"
â†’ Searches knowledge base
â†’ Uses retrieved cooking instructions
â†’ Answer: Detailed recipe with measurements from KB

RAG Mode OFF:
User: "How to make bread dough?"
â†’ No knowledge base search
â†’ Pure Phi-2 knowledge
â†’ Answer: General bread-making info from model training
â†’ May be less specific or domain-focused
```

### Example 5: Memory Clear Demo
```
Session 1:
User: "My favorite cuisine is Thai"
Bot: "Thai cuisine is wonderful! Would you like recipes?"
User: "What's my favorite cuisine?"
Bot: "You mentioned Thai cuisine is your favorite."

[User clicks "Clear Memory"]

Session 2:
User: "What's my favorite cuisine?"
Bot: "I don't have information about your favorite cuisine. 
      Could you tell me?"
```

---

**This architecture balances:**
- âš¡ Speed (small model)
- ğŸ¯ Accuracy (RAG retrieval)
- ğŸ’¾ Memory (conversation context)
- ğŸ”§ Flexibility (easy to extend)
